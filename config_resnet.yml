# Configuration for MART Adversarial Training Privacy Evaluation

# --- Data Configuration ---
data:
  name: 'CIFAR-10'       # Dataset name (e.g., 'MNIST', 'CIFAR-10')
  path: './data'         # Path to download/load the dataset
  num_classes: 10        # Number of classes in the dataset

# --- Model Configuration ---
model:
  name: 'ResNet'       # Model architecture name
  depth: 18               # WRN depth (e.g., 28, 34)

# --- Training Configuration ---
training:
  epochs: 120              # Total number of training epochs
  batch_size: 256          # Batch size for training
  optimizer:
    name: 'SGD'            # Optimizer name ('SGD', 'Adam', etc.)
    params:
      lr: 0.01               # Initial learning rate
      momentum: 0.9         # Momentum for SGD
      weight_decay: 0.0035  # Weight decay (L2 regularization)
  lr_scheduler:
    name: 'MultiStepLR'    # Learning rate scheduler ('StepLR', 'MultiStepLR', 'CosineAnnealingLR')
    params:
      milestones: [75, 90] # Epochs at which to decay LR (for MultiStepLR)
      gamma: 0.1            # LR decay factor


# --- Adversarial Training / Attack Configuration ---
adversarial:
  method: 'MART'           # Training method ('MART', 'Standard', 'PGD_AT') - Standard would skip adv examples
  epsilon: 0.03137         # Perturbation budget (e.g., 8/255)

  # Settings for the PGD attack *during training* (used by create_adv_samples in train_adv_one_epoch)
  train_attack:
    num_steps: 10          # PGD steps for generating training examples
    step_size: 0.00784     # PGD step size (e.g., 2/255) - often eps/4 or 2*eps/num_steps
    random_start: True     # Use random start for PGD

# --- MART Specific Configuration ---
mart:
  lambda_reg: 5.0          # MART regularization parameter (beta in the paper)

# --- Validation / Evaluation Configuration ---
validation:
  frequency: 1             # How often to run validation (e.g., every 1 epoch)
  batch_size: 512          # Batch size for validation (can often be larger)

  # Settings for the PGD attack *during validation/testing*
  eval_attack:
    num_steps: 20          # Use a stronger attack for evaluation
    step_size: 0.003       # Step size for evaluation attack (can be smaller)
    random_start: True

logging:
  log_dir: './results/logs/resnet'         # Directory for logs (TensorBoard, CSV, etc.)
  checkpoint_dir: './results/models/resnet' # Directory to save model checkpoints
  save_frequency: 10               # Save checkpoint every N epochs (0 to disable intermediate saves)
  save_best_only: True             # Only save checkpoint if validation accuracy improves

# --- Environment ---
environment:
  device: 'cuda'           # Device to use ('cuda', 'cpu')
  seed: 12345678                 # Random seed for reproducibility