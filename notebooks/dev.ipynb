{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 14 18:39:48 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:01:00.0 Off |                   On |\n",
      "| N/A   24C    P0             49W /  500W |      88MiB /  81920MiB |     N/A      Default |\n",
      "|                                         |                        |            Disabled* |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          Off |   00000000:41:00.0 Off |                   On |\n",
      "| N/A   24C    P0             59W /  500W |    5763MiB /  81920MiB |     N/A      Default |\n",
      "|                                         |                        |            Disabled* |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-80GB          Off |   00000000:81:00.0 Off |                   On |\n",
      "| N/A   22C    P0             46W /  500W |      88MiB /  81920MiB |     N/A      Default |\n",
      "|                                         |                        |            Disabled* |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-80GB          Off |   00000000:C1:00.0 Off |                   On |\n",
      "| N/A   29C    P0             91W /  500W |    7165MiB /  81920MiB |     N/A      Default |\n",
      "|                                         |                        |            Disabled* |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                            |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |                     Memory-Usage |        Vol|        Shared         |\n",
      "|      ID  ID  Dev |                       BAR1-Usage | SM     Unc| CE ENC  DEC  OFA  JPG |\n",
      "|                  |                                  |        ECC|                       |\n",
      "|==================+==================================+===========+=======================|\n",
      "|  0    1   0   0  |              38MiB / 40192MiB    | 42      0 |  3   0    2    0    0 |\n",
      "|                  |                 0MiB / 65535MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  0    5   0   1  |              25MiB / 19968MiB    | 28      0 |  2   0    1    0    0 |\n",
      "|                  |                 0MiB / 32767MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  0   13   0   2  |              13MiB /  9728MiB    | 14      0 |  1   0    0    0    0 |\n",
      "|                  |                 0MiB / 16383MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  0   14   0   3  |              13MiB /  9728MiB    | 14      0 |  1   0    0    0    0 |\n",
      "|                  |                 0MiB / 16383MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  1    1   0   0  |            5713MiB / 40192MiB    | 42      0 |  3   0    2    0    0 |\n",
      "|                  |                 2MiB / 65535MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  1    5   0   1  |              25MiB / 19968MiB    | 28      0 |  2   0    1    0    0 |\n",
      "|                  |                 0MiB / 32767MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  1   13   0   2  |              13MiB /  9728MiB    | 14      0 |  1   0    0    0    0 |\n",
      "|                  |                 0MiB / 16383MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  1   14   0   3  |              13MiB /  9728MiB    | 14      0 |  1   0    0    0    0 |\n",
      "|                  |                 0MiB / 16383MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  2    2   0   0  |              38MiB / 40192MiB    | 42      0 |  3   0    2    0    0 |\n",
      "|                  |                 0MiB / 65535MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  2    3   0   1  |              25MiB / 19968MiB    | 28      0 |  2   0    1    0    0 |\n",
      "|                  |                 0MiB / 32767MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  2    9   0   2  |              13MiB /  9728MiB    | 14      0 |  1   0    0    0    0 |\n",
      "|                  |                 0MiB / 16383MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  2   10   0   3  |              13MiB /  9728MiB    | 14      0 |  1   0    0    0    0 |\n",
      "|                  |                 0MiB / 16383MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  3    2   0   0  |              38MiB / 40192MiB    | 42      0 |  3   0    2    0    0 |\n",
      "|                  |                 0MiB / 65535MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  3    3   0   1  |              25MiB / 19968MiB    | 28      0 |  2   0    1    0    0 |\n",
      "|                  |                 0MiB / 32767MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  3    9   0   2  |            3250MiB /  9728MiB    | 14      0 |  1   0    0    0    0 |\n",
      "|                  |                 2MiB / 16383MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "|  3   10   0   3  |            3852MiB /  9728MiB    | 14      0 |  1   0    0    0    0 |\n",
      "|                  |                 2MiB / 16383MiB  |           |                       |\n",
      "+------------------+----------------------------------+-----------+-----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    1    1    0     670466      C   /home/yyu27/py38/bin/python                  5666MiB |\n",
      "|    3    9    0     694453      C   python                                       3230MiB |\n",
      "|    3   10    0     694813      C   python                                       3832MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOCAL CLUSTER DIRECTORY FILE LOADING\n",
    "# import pickle\n",
    "\n",
    "# # Function to unpickle the dataset files\n",
    "# def unpickle(file):\n",
    "#     with open(file, 'rb') as fo:\n",
    "#         data_dict = pickle.load(fo, encoding='bytes')\n",
    "#     return data_dict\n",
    "\n",
    "# # Function to load all data batches\n",
    "# def load_data(batch_files):\n",
    "#     all_data = []\n",
    "#     all_labels = []\n",
    "#     for batch_file in batch_files:\n",
    "#         batch_file = DATASET_PATH + batch_file\n",
    "#         batch = unpickle(batch_file)\n",
    "#         all_data.append(batch[b'data'])  # Image data\n",
    "#         all_labels.append(batch[b'labels'])  # Labels\n",
    "#     data = np.concatenate(all_data)\n",
    "#     labels = np.concatenate(all_labels)\n",
    "#     return data, labels\n",
    "\n",
    "# # Function to reshape image data\n",
    "# def reshape_images(data):\n",
    "#     # Reshape from (10000, 3072) to (10000, 32, 32, 3)\n",
    "#     data = data.reshape(-1, 3, 32, 32)  # (10000, 3, 32, 32)\n",
    "#     data = data.transpose(0, 2, 3, 1)  # (10000, 32, 32, 3)\n",
    "#     return data\n",
    "\n",
    "# # Load metadata (label names)\n",
    "# def load_meta(file):\n",
    "#     file = DATASET_PATH + file\n",
    "#     meta = unpickle(file)\n",
    "#     label_names = [name.decode('utf-8') for name in meta[b'label_names']]  # Decode bytes to strings\n",
    "#     return label_names\n",
    "\n",
    "# # Example usage\n",
    "# # Files for the training batches and metadata\n",
    "# batch_files = ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n",
    "# DATASET_PATH = \"/datasets/CS747/cifar-10-batches-py/\"\n",
    "# test_batch_file = 'test_batch'\n",
    "# meta_file = 'batches.meta'\n",
    "\n",
    "# # Load training data\n",
    "# data, labels = load_data(batch_files)\n",
    "# data = reshape_images(data)  # Reshape image data into (10000, 32, 32, 3)\n",
    "\n",
    "# # Load test data\n",
    "# test_data, test_labels = load_data([test_batch_file])\n",
    "# test_data = reshape_images(test_data)  # Reshape test data into (10000, 32, 32, 3)\n",
    "\n",
    "# # Load label names (metadata)\n",
    "# label_names = load_meta(meta_file)\n",
    "\n",
    "# # Example of accessing one image and its label:\n",
    "# image_index = 3\n",
    "# image = data[image_index]  # 32x32x3 image\n",
    "# label = labels[image_index]\n",
    "# label_name = label_names[label]\n",
    "\n",
    "# print(f\"Image shape: {image.shape}, Label: {label}, Label name: {label_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data loader\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# LOAD FROM TORCHVISION\n",
    "\n",
    "train_mnist = datasets.MNIST(root='./data', download=True, train=True, transform=transforms.ToTensor())\n",
    "test_mnist = datasets.MNIST(root='./data', download=True, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "#transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "full_train_cifar = datasets.CIFAR10(root='./data', download=True, train=True, transform=transform_train)\n",
    "test_cifar = datasets.CIFAR10(root='./data', download=True, train=False, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sizes for split (e.g., 90% training, 10% validation)\n",
    "num_train = int(0.9 * len(full_train_cifar))  # 45,000 images\n",
    "num_val = len(full_train_cifar) - num_train    # 5,000 images\n",
    "\n",
    "train_dataset, val_dataset = random_split(full_train_cifar, [num_train, num_val])\n",
    "\n",
    "train_loader_cifar = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_cifar = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE*2, shuffle=False)\n",
    "test_loader_cifar = DataLoader(dataset=test_cifar, batch_size=BATCH_SIZE*2, shuffle=False)\n",
    "\n",
    "train_loader_mnist = DataLoader(dataset=train_mnist, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST CNN CONFIGS\n",
    "\n",
    "mnist_cnn_config = {\n",
    "    \"learning_rate\" : 0.01, # learning rate\n",
    "    \"weight_decay\" : 3.5e-5,\n",
    "    }\n",
    "\n",
    "cifar_config = {\n",
    "    \"learning_rate\" : 0.01,\n",
    "    \"weight_decay\" : 3.5e-5,\n",
    "    \"epochs\": 100\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, drop=0.5):\n",
    "        super(SmallCNN, self).__init__()\n",
    "\n",
    "        self.num_channels = 1\n",
    "        self.num_labels = 10\n",
    "\n",
    "        activ = nn.ReLU(True)\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(self.num_channels, 32, 3)),\n",
    "            ('relu1', activ),\n",
    "            ('conv2', nn.Conv2d(32, 32, 3)),\n",
    "            ('relu2', activ),\n",
    "            ('maxpool1', nn.MaxPool2d(2, 2)),\n",
    "            ('conv3', nn.Conv2d(32, 64, 3)),\n",
    "            ('relu3', activ),\n",
    "            ('conv4', nn.Conv2d(64, 64, 3)),\n",
    "            ('relu4', activ),\n",
    "            ('maxpool2', nn.MaxPool2d(2, 2)),\n",
    "        ]))\n",
    "\n",
    "        self.classifier = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(64 * 4 * 4, 200)),\n",
    "            ('relu1', activ),\n",
    "            ('drop', nn.Dropout(drop)),\n",
    "            ('fc2', nn.Linear(200, 200)),\n",
    "            ('relu2', activ),\n",
    "            ('fc3', nn.Linear(200, self.num_labels)),\n",
    "        ]))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d)):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        nn.init.constant_(self.classifier.fc3.weight, 0)\n",
    "        nn.init.constant_(self.classifier.fc3.bias, 0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        features = self.feature_extractor(input)\n",
    "        #print(features.shape)\n",
    "        logits = self.classifier(features.view(-1, 64 * 4 * 4))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resnet Model\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.residual = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = F.relu(self.bn2(self.conv2(out)), inplace=True)\n",
    "        out = out + self.residual(x)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block: BasicBlock, num_blocks: list[int], num_classes: int=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer0 = self.make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer1 = self.make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer2 = self.make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer3 = self.make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "\n",
    "    \n",
    "    def make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "\n",
    "        layers.append(block(self.in_channels, out_channels, stride=stride))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = self.layer0(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        logits = self.linear(out)\n",
    "        return logits\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_test = ResNet18().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_rand = torch.randn((1, 3, 32, 32)).cuda()\n",
    "# print(x_rand.shape)\n",
    "# output = model_test(x_rand)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model,  dataloader, criterion, optimizer, device, max_grad_norm=None):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        if max_grad_norm:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = torch.argmax(outputs.detach(), -1)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        total_samples += images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects / total_samples\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc = 'Validation', leave=False):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            preds = torch.argmax(outputs, -1)\n",
    "            running_corrects += torch.sum((preds == labels)).item()\n",
    "            total_samples += labels.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = running_corrects / total_samples\n",
    "\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "# def adjust_learning_rate(optimizer, epoch, config):\n",
    "#     \"\"\"decrease the learning rate\"\"\"\n",
    "#     lr = config[\"learning_rate\"]\n",
    "\n",
    "#     if epoch >= 100:\n",
    "#         lr = config[\"learning_rate\"] * 0.001\n",
    "#     elif epoch >= 90:\n",
    "#         lr = config[\"learning_rate\"] * 0.01\n",
    "#     elif epoch >= 75:\n",
    "#         lr = config[\"learning_rate\"] * 0.1\n",
    "\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, val_loss, checkpoint_dir, top_checkpoints, max_checkpoints=5):\n",
    "    \"\"\"\n",
    "    Save a checkpoint if it's among the top best ones.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to save.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer state to save.\n",
    "        epoch (int): The current epoch.\n",
    "        val_loss (float): The validation loss metric used for ranking.\n",
    "        checkpoint_dir (str): Directory to save the checkpoints.\n",
    "        top_checkpoints (list): List of tuples (val_loss, filename) for current top checkpoints.\n",
    "        max_checkpoints (int, optional): Maximum number of checkpoints to save. Defaults to 5.\n",
    "    \"\"\"\n",
    "    # Ensure the checkpoint directory exists.\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Construct a filename that contains the epoch and validation loss.\n",
    "    checkpoint_filename = os.path.join(checkpoint_dir, f\"model_epoch_{epoch+1}_valloss_{val_loss:.4f}.pth\")\n",
    "    \n",
    "    # Create the checkpoint dictionary\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "    }\n",
    "    \n",
    "    # Save checkpoint to disk\n",
    "    torch.save(checkpoint, checkpoint_filename)\n",
    "    \n",
    "    # Add the checkpoint to your top checkpoints list (we assume lower loss is better)\n",
    "    top_checkpoints.append((val_loss, checkpoint_filename))\n",
    "    \n",
    "    # Sort the checkpoints by validation loss (ascending order)\n",
    "    top_checkpoints.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # If more than max_checkpoints, delete the worst checkpoint (last one in sorted list)\n",
    "    if len(top_checkpoints) > max_checkpoints:\n",
    "        worst_checkpoint = top_checkpoints.pop()  # pop the highest loss checkpoint\n",
    "        if os.path.exists(worst_checkpoint[1]):\n",
    "            os.remove(worst_checkpoint[1])\n",
    "            print(f\"Removed checkpoint: {worst_checkpoint[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, config, scheduler=None, device=\"cuda\"):\n",
    "    num_epochs = config[\"epochs\"]\n",
    "    \n",
    "    top_checkpoints = []\n",
    "    checkpoint_dir = config.get(\"checkpoint_dir\", \"./checkpoints\")\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\" : [],\n",
    "        \"train_acc\" : [],\n",
    "        \"val_loss\" : [],\n",
    "        \"val_acc\" : []\n",
    "    }\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), \n",
    "                    lr = config[\"learning_rate\"], \n",
    "                    momentum= 0.9,\n",
    "                    weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    scheduler = MultiStepLR(optimizer=optimizer, milestones= [75, 90, 100], gamma=0.1)\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        #print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "\n",
    "        #adjust_learning_rate(optimizer, epoch, config=config)\n",
    "\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model = model, dataloader = train_loader, \n",
    "            criterion=criterion, optimizer=optimizer, \n",
    "            device=device, max_grad_norm=1.0\n",
    "        )\n",
    "\n",
    "        val_loss, val_acc = validate(model=model, dataloader=val_loader, criterion=criterion, device=device)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] | \"\n",
    "              f\"LR: {scheduler.get_last_lr()[0]:.3f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        save_checkpoint(model, optimizer, epoch, val_loss, checkpoint_dir, top_checkpoints, max_checkpoints=5)\n",
    "        \n",
    "    \n",
    "\n",
    "    return model, history, top_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = ResNet18().to(device)\n",
    "\n",
    "    model, history = train_model(model, \n",
    "                                 train_loader=train_loader_cifar, \n",
    "                                 val_loader=val_loader_cifar,\n",
    "                                 config= cifar_config\n",
    "    )\n",
    "\n",
    "    print(\"Training Done\")\n",
    "    print('================================================================')\n",
    "\n",
    "    test_loss, test_acc = validate(model, dataloader=test_loader_cifar, criterion=nn.CrossEntropyLoss(), device=device)\n",
    "    print(f\"Test accuracy: {test_acc}, Test loss: {test_loss}\")\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/352 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] | LR: 0.010 | Train Loss: 1.5923 | Train Acc: 41.05% | Val Loss: 1.3970 | Val Acc: 47.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100] | LR: 0.010 | Train Loss: 1.1824 | Train Acc: 57.12% | Val Loss: 1.5524 | Val Acc: 49.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100] | LR: 0.010 | Train Loss: 0.9979 | Train Acc: 64.37% | Val Loss: 1.1023 | Val Acc: 60.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100] | LR: 0.010 | Train Loss: 0.8744 | Train Acc: 68.76% | Val Loss: 0.9641 | Val Acc: 65.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100] | LR: 0.010 | Train Loss: 0.7826 | Train Acc: 72.30% | Val Loss: 0.8617 | Val Acc: 70.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100] | LR: 0.010 | Train Loss: 0.6932 | Train Acc: 75.62% | Val Loss: 0.9013 | Val Acc: 68.76%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_3_valloss_1.5524.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100] | LR: 0.010 | Train Loss: 0.6305 | Train Acc: 77.91% | Val Loss: 0.6746 | Val Acc: 76.16%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_2_valloss_1.3970.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100] | LR: 0.010 | Train Loss: 0.5816 | Train Acc: 79.88% | Val Loss: 0.9722 | Val Acc: 68.02%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_4_valloss_1.1023.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100] | LR: 0.010 | Train Loss: 0.5369 | Train Acc: 81.25% | Val Loss: 0.7006 | Val Acc: 76.18%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_9_valloss_0.9722.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100] | LR: 0.010 | Train Loss: 0.4976 | Train Acc: 82.53% | Val Loss: 0.5604 | Val Acc: 80.62%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_5_valloss_0.9641.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100] | LR: 0.010 | Train Loss: 0.4661 | Train Acc: 83.73% | Val Loss: 0.5593 | Val Acc: 80.24%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_7_valloss_0.9013.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100] | LR: 0.010 | Train Loss: 0.4401 | Train Acc: 84.71% | Val Loss: 0.5446 | Val Acc: 81.28%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_6_valloss_0.8617.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100] | LR: 0.010 | Train Loss: 0.4122 | Train Acc: 85.65% | Val Loss: 0.6718 | Val Acc: 77.42%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_10_valloss_0.7006.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100] | LR: 0.010 | Train Loss: 0.3885 | Train Acc: 86.37% | Val Loss: 0.5752 | Val Acc: 80.70%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_8_valloss_0.6746.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100] | LR: 0.010 | Train Loss: 0.3659 | Train Acc: 87.35% | Val Loss: 0.5365 | Val Acc: 82.02%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_14_valloss_0.6718.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100] | LR: 0.010 | Train Loss: 0.3505 | Train Acc: 87.95% | Val Loss: 0.6019 | Val Acc: 80.12%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_17_valloss_0.6019.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100] | LR: 0.010 | Train Loss: 0.3266 | Train Acc: 88.68% | Val Loss: 0.4566 | Val Acc: 84.00%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_15_valloss_0.5752.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100] | LR: 0.010 | Train Loss: 0.3142 | Train Acc: 89.07% | Val Loss: 0.4780 | Val Acc: 83.96%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_11_valloss_0.5604.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100] | LR: 0.010 | Train Loss: 0.2924 | Train Acc: 89.85% | Val Loss: 0.5462 | Val Acc: 82.44%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_12_valloss_0.5593.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100] | LR: 0.010 | Train Loss: 0.2866 | Train Acc: 90.02% | Val Loss: 0.5038 | Val Acc: 83.52%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_20_valloss_0.5462.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100] | LR: 0.010 | Train Loss: 0.2680 | Train Acc: 90.73% | Val Loss: 0.5630 | Val Acc: 82.72%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_22_valloss_0.5630.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100] | LR: 0.010 | Train Loss: 0.2571 | Train Acc: 90.91% | Val Loss: 0.5002 | Val Acc: 83.82%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_13_valloss_0.5446.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100] | LR: 0.010 | Train Loss: 0.2447 | Train Acc: 91.57% | Val Loss: 0.4816 | Val Acc: 84.78%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_16_valloss_0.5365.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100] | LR: 0.010 | Train Loss: 0.2326 | Train Acc: 91.65% | Val Loss: 0.4467 | Val Acc: 85.82%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_21_valloss_0.5038.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100] | LR: 0.010 | Train Loss: 0.2237 | Train Acc: 92.23% | Val Loss: 0.4381 | Val Acc: 85.84%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_23_valloss_0.5002.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100] | LR: 0.010 | Train Loss: 0.2120 | Train Acc: 92.50% | Val Loss: 0.5084 | Val Acc: 84.52%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_27_valloss_0.5084.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100] | LR: 0.010 | Train Loss: 0.2007 | Train Acc: 92.94% | Val Loss: 0.4134 | Val Acc: 86.58%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_24_valloss_0.4816.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100] | LR: 0.010 | Train Loss: 0.1877 | Train Acc: 93.34% | Val Loss: 0.4866 | Val Acc: 85.06%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_29_valloss_0.4866.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100] | LR: 0.010 | Train Loss: 0.1817 | Train Acc: 93.64% | Val Loss: 0.6008 | Val Acc: 83.70%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_30_valloss_0.6008.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100] | LR: 0.010 | Train Loss: 0.1779 | Train Acc: 93.79% | Val Loss: 0.4546 | Val Acc: 86.38%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_19_valloss_0.4780.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100] | LR: 0.010 | Train Loss: 0.1679 | Train Acc: 94.09% | Val Loss: 0.4727 | Val Acc: 86.16%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_32_valloss_0.4727.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100] | LR: 0.010 | Train Loss: 0.1586 | Train Acc: 94.34% | Val Loss: 0.4929 | Val Acc: 85.54%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_33_valloss_0.4929.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100] | LR: 0.010 | Train Loss: 0.1580 | Train Acc: 94.36% | Val Loss: 0.4285 | Val Acc: 87.30%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_18_valloss_0.4566.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100] | LR: 0.010 | Train Loss: 0.1460 | Train Acc: 94.86% | Val Loss: 0.5633 | Val Acc: 84.60%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_35_valloss_0.5633.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100] | LR: 0.010 | Train Loss: 0.1426 | Train Acc: 95.01% | Val Loss: 0.4684 | Val Acc: 85.90%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_36_valloss_0.4684.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100] | LR: 0.010 | Train Loss: 0.1360 | Train Acc: 95.18% | Val Loss: 0.5018 | Val Acc: 84.96%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_37_valloss_0.5018.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100] | LR: 0.010 | Train Loss: 0.1253 | Train Acc: 95.61% | Val Loss: 0.4286 | Val Acc: 87.24%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_31_valloss_0.4546.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100] | LR: 0.010 | Train Loss: 0.1240 | Train Acc: 95.62% | Val Loss: 0.4194 | Val Acc: 87.42%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_25_valloss_0.4467.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100] | LR: 0.010 | Train Loss: 0.1219 | Train Acc: 95.75% | Val Loss: 0.4666 | Val Acc: 86.66%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_40_valloss_0.4666.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100] | LR: 0.010 | Train Loss: 0.1157 | Train Acc: 95.93% | Val Loss: 0.4387 | Val Acc: 87.52%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_41_valloss_0.4387.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100] | LR: 0.010 | Train Loss: 0.1074 | Train Acc: 96.15% | Val Loss: 0.4681 | Val Acc: 86.78%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_42_valloss_0.4681.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100] | LR: 0.010 | Train Loss: 0.1053 | Train Acc: 96.31% | Val Loss: 0.4729 | Val Acc: 86.78%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_43_valloss_0.4729.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100] | LR: 0.010 | Train Loss: 0.1036 | Train Acc: 96.36% | Val Loss: 0.5232 | Val Acc: 85.66%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_44_valloss_0.5232.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100] | LR: 0.010 | Train Loss: 0.0979 | Train Acc: 96.55% | Val Loss: 0.4658 | Val Acc: 87.34%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_45_valloss_0.4658.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100] | LR: 0.010 | Train Loss: 0.0951 | Train Acc: 96.73% | Val Loss: 0.4496 | Val Acc: 87.16%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_46_valloss_0.4496.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100] | LR: 0.010 | Train Loss: 0.0932 | Train Acc: 96.69% | Val Loss: 0.6077 | Val Acc: 85.28%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_47_valloss_0.6077.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100] | LR: 0.010 | Train Loss: 0.0900 | Train Acc: 96.78% | Val Loss: 0.4750 | Val Acc: 87.60%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_48_valloss_0.4750.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100] | LR: 0.010 | Train Loss: 0.0890 | Train Acc: 96.78% | Val Loss: 0.4472 | Val Acc: 87.68%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_49_valloss_0.4472.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100] | LR: 0.010 | Train Loss: 0.0816 | Train Acc: 97.12% | Val Loss: 0.5545 | Val Acc: 86.24%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_50_valloss_0.5545.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100] | LR: 0.010 | Train Loss: 0.0834 | Train Acc: 97.11% | Val Loss: 0.5834 | Val Acc: 85.06%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_51_valloss_0.5834.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100] | LR: 0.010 | Train Loss: 0.0779 | Train Acc: 97.30% | Val Loss: 0.4439 | Val Acc: 88.62%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_52_valloss_0.4439.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100] | LR: 0.010 | Train Loss: 0.0751 | Train Acc: 97.35% | Val Loss: 0.4739 | Val Acc: 88.42%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_53_valloss_0.4739.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100] | LR: 0.010 | Train Loss: 0.0729 | Train Acc: 97.45% | Val Loss: 0.5144 | Val Acc: 87.54%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_54_valloss_0.5144.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100] | LR: 0.010 | Train Loss: 0.0716 | Train Acc: 97.40% | Val Loss: 0.5253 | Val Acc: 87.32%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_55_valloss_0.5253.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100] | LR: 0.010 | Train Loss: 0.0706 | Train Acc: 97.44% | Val Loss: 0.5555 | Val Acc: 85.96%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_56_valloss_0.5555.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100] | LR: 0.010 | Train Loss: 0.0688 | Train Acc: 97.59% | Val Loss: 0.5357 | Val Acc: 87.02%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_57_valloss_0.5357.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100] | LR: 0.010 | Train Loss: 0.0644 | Train Acc: 97.69% | Val Loss: 0.4884 | Val Acc: 87.88%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_58_valloss_0.4884.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100] | LR: 0.010 | Train Loss: 0.0655 | Train Acc: 97.67% | Val Loss: 0.4522 | Val Acc: 88.94%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_59_valloss_0.4522.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100] | LR: 0.010 | Train Loss: 0.0602 | Train Acc: 97.84% | Val Loss: 0.4370 | Val Acc: 88.88%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_26_valloss_0.4381.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100] | LR: 0.010 | Train Loss: 0.0631 | Train Acc: 97.80% | Val Loss: 0.5179 | Val Acc: 87.90%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_61_valloss_0.5179.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100] | LR: 0.010 | Train Loss: 0.0621 | Train Acc: 97.82% | Val Loss: 0.4662 | Val Acc: 88.38%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_62_valloss_0.4662.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100] | LR: 0.010 | Train Loss: 0.0576 | Train Acc: 97.97% | Val Loss: 0.5007 | Val Acc: 88.22%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_63_valloss_0.5007.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100] | LR: 0.010 | Train Loss: 0.0568 | Train Acc: 98.03% | Val Loss: 0.4974 | Val Acc: 88.34%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_64_valloss_0.4974.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100] | LR: 0.010 | Train Loss: 0.0565 | Train Acc: 97.96% | Val Loss: 0.5001 | Val Acc: 88.26%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_65_valloss_0.5001.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100] | LR: 0.010 | Train Loss: 0.0533 | Train Acc: 98.09% | Val Loss: 0.5265 | Val Acc: 87.52%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_66_valloss_0.5265.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100] | LR: 0.010 | Train Loss: 0.0493 | Train Acc: 98.29% | Val Loss: 0.5054 | Val Acc: 88.66%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_67_valloss_0.5054.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100] | LR: 0.010 | Train Loss: 0.0529 | Train Acc: 98.16% | Val Loss: 0.4860 | Val Acc: 88.86%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_68_valloss_0.4860.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100] | LR: 0.010 | Train Loss: 0.0500 | Train Acc: 98.21% | Val Loss: 0.5265 | Val Acc: 87.74%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_69_valloss_0.5265.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100] | LR: 0.010 | Train Loss: 0.0507 | Train Acc: 98.19% | Val Loss: 0.5325 | Val Acc: 88.20%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_70_valloss_0.5325.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100] | LR: 0.010 | Train Loss: 0.0489 | Train Acc: 98.27% | Val Loss: 0.4866 | Val Acc: 88.54%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_71_valloss_0.4866.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100] | LR: 0.010 | Train Loss: 0.0472 | Train Acc: 98.40% | Val Loss: 0.5315 | Val Acc: 88.34%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_72_valloss_0.5315.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100] | LR: 0.010 | Train Loss: 0.0484 | Train Acc: 98.24% | Val Loss: 0.5775 | Val Acc: 87.18%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_73_valloss_0.5775.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100] | LR: 0.010 | Train Loss: 0.0474 | Train Acc: 98.33% | Val Loss: 0.5114 | Val Acc: 88.74%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_74_valloss_0.5114.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100] | LR: 0.010 | Train Loss: 0.0450 | Train Acc: 98.44% | Val Loss: 0.5152 | Val Acc: 88.84%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_75_valloss_0.5152.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100] | LR: 0.010 | Train Loss: 0.0458 | Train Acc: 98.38% | Val Loss: 0.4955 | Val Acc: 88.78%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_76_valloss_0.4955.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100] | LR: 0.001 | Train Loss: 0.0203 | Train Acc: 99.32% | Val Loss: 0.4125 | Val Acc: 90.46%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_60_valloss_0.4370.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100] | LR: 0.001 | Train Loss: 0.0110 | Train Acc: 99.69% | Val Loss: 0.3907 | Val Acc: 90.60%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_38_valloss_0.4286.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100] | LR: 0.001 | Train Loss: 0.0099 | Train Acc: 99.70% | Val Loss: 0.4019 | Val Acc: 90.52%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_34_valloss_0.4285.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100] | LR: 0.001 | Train Loss: 0.0081 | Train Acc: 99.78% | Val Loss: 0.4111 | Val Acc: 90.66%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_39_valloss_0.4194.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100] | LR: 0.001 | Train Loss: 0.0067 | Train Acc: 99.84% | Val Loss: 0.4019 | Val Acc: 91.08%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_28_valloss_0.4134.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100] | LR: 0.001 | Train Loss: 0.0065 | Train Acc: 99.84% | Val Loss: 0.3964 | Val Acc: 90.92%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_77_valloss_0.4125.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100] | LR: 0.001 | Train Loss: 0.0060 | Train Acc: 99.86% | Val Loss: 0.3893 | Val Acc: 91.02%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_80_valloss_0.4111.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100] | LR: 0.001 | Train Loss: 0.0054 | Train Acc: 99.86% | Val Loss: 0.3908 | Val Acc: 91.26%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_81_valloss_0.4019.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100] | LR: 0.001 | Train Loss: 0.0045 | Train Acc: 99.90% | Val Loss: 0.3982 | Val Acc: 91.06%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_79_valloss_0.4019.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100] | LR: 0.001 | Train Loss: 0.0047 | Train Acc: 99.91% | Val Loss: 0.4135 | Val Acc: 91.08%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_86_valloss_0.4135.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100] | LR: 0.001 | Train Loss: 0.0043 | Train Acc: 99.93% | Val Loss: 0.3925 | Val Acc: 91.06%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_85_valloss_0.3982.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100] | LR: 0.001 | Train Loss: 0.0037 | Train Acc: 99.93% | Val Loss: 0.4181 | Val Acc: 90.74%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_88_valloss_0.4181.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100] | LR: 0.001 | Train Loss: 0.0037 | Train Acc: 99.94% | Val Loss: 0.4232 | Val Acc: 90.94%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_89_valloss_0.4232.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100] | LR: 0.001 | Train Loss: 0.0034 | Train Acc: 99.95% | Val Loss: 0.4161 | Val Acc: 91.08%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_90_valloss_0.4161.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100] | LR: 0.001 | Train Loss: 0.0033 | Train Acc: 99.95% | Val Loss: 0.4019 | Val Acc: 91.02%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_91_valloss_0.4019.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100] | LR: 0.000 | Train Loss: 0.0030 | Train Acc: 99.95% | Val Loss: 0.4311 | Val Acc: 91.02%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_92_valloss_0.4311.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100] | LR: 0.000 | Train Loss: 0.0032 | Train Acc: 99.94% | Val Loss: 0.4220 | Val Acc: 91.32%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_93_valloss_0.4220.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100] | LR: 0.000 | Train Loss: 0.0030 | Train Acc: 99.95% | Val Loss: 0.4215 | Val Acc: 91.00%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_94_valloss_0.4215.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100] | LR: 0.000 | Train Loss: 0.0029 | Train Acc: 99.95% | Val Loss: 0.4081 | Val Acc: 90.94%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_95_valloss_0.4081.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100] | LR: 0.000 | Train Loss: 0.0032 | Train Acc: 99.94% | Val Loss: 0.4125 | Val Acc: 91.12%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_96_valloss_0.4125.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100] | LR: 0.000 | Train Loss: 0.0028 | Train Acc: 99.96% | Val Loss: 0.4069 | Val Acc: 91.34%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_97_valloss_0.4069.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100] | LR: 0.000 | Train Loss: 0.0030 | Train Acc: 99.95% | Val Loss: 0.3978 | Val Acc: 91.40%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_98_valloss_0.3978.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100] | LR: 0.000 | Train Loss: 0.0031 | Train Acc: 99.94% | Val Loss: 0.4304 | Val Acc: 90.88%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_99_valloss_0.4304.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100] | LR: 0.000 | Train Loss: 0.0028 | Train Acc: 99.95% | Val Loss: 0.4165 | Val Acc: 90.82%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_100_valloss_0.4165.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100] | LR: 0.000 | Train Loss: 0.0027 | Train Acc: 99.95% | Val Loss: 0.4339 | Val Acc: 90.74%\n",
      "Removed checkpoint: ./checkpoints/model_epoch_101_valloss_0.4339.pth\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 4\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m ResNet18()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 4\u001b[0m     model, history \u001b[38;5;241m=\u001b[39m train_model(model, \n\u001b[1;32m      5\u001b[0m                                  train_loader\u001b[38;5;241m=\u001b[39mtrain_loader_cifar, \n\u001b[1;32m      6\u001b[0m                                  val_loader\u001b[38;5;241m=\u001b[39mval_loader_cifar,\n\u001b[1;32m      7\u001b[0m                                  config\u001b[38;5;241m=\u001b[39m cifar_config\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m================================================================\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    history = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, test_acc = validate(model, dataloader=test_loader_cifar, criterion=nn.CrossEntropyLoss(), device=device)\n",
    "# print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adver training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adv_samples(model, inputs, labels, config, random_start=True):\n",
    "    epsilon = config[\"epsilon\"]\n",
    "    step_size = config[\"step_size\"]\n",
    "    num_steps = config[\"num_steps\"]\n",
    "    #norm = config[\"norm\"]\n",
    "\n",
    "    model.eval()\n",
    "    # Keep original clean samples\n",
    "    x_clean = inputs.clone().detach()\n",
    "\n",
    "\n",
    "    if random_start:\n",
    "        delta = torch.rand_like(inputs, device=device) * 2 * epsilon - epsilon\n",
    "    else:\n",
    "        delta = torch.zeros_like(inputs, device=device)\n",
    "    \n",
    "    delta = torch.clamp(delta, -epsilon, epsilon)\n",
    "    delta.requires_grad = True\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        x_adv = x_clean + delta\n",
    "        \n",
    "        # for stable batch norm stats and to disable dropout\n",
    "        with torch.enable_grad():\n",
    "            outputs = model(x_adv)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        grad = torch.autograd.grad(loss, delta)[0]\n",
    "        delta = delta.detach() + step_size * torch.sign(grad)\n",
    "        delta = torch.clamp(delta, -epsilon, epsilon)\n",
    "\n",
    "        # clamp adversarial sample to valid pixel range        \n",
    "        x_adv_clamped = torch.clamp(x_clean + delta, 0.0, 1.0)\n",
    "        \n",
    "        # get accurate delat from clamped x\n",
    "        delta = x_adv_clamped - x_clean\n",
    "        delta = delta.detach()\n",
    "        \n",
    "        if step < num_steps - 1:\n",
    "            delta.requires_grad = True\n",
    "    \n",
    "    # final adversarial sample\n",
    "    x_adv_batch = (x_clean + delta).detach()\n",
    "\n",
    "    return x_adv_batch\n",
    "\n",
    "\n",
    "def mart_loss(logits_clean, logits_adv, labels, lambda_reg):\n",
    "    # BCE LOSS = standard cross entropy + margin maximization\n",
    "    # get the probabilty distribution for the adversarial logits\n",
    "    probs_adv = F.softmax(logits_adv, dim=-1)\n",
    "\n",
    "    # sort it and get the two highest values/prediction\n",
    "    tmp1 = torch.argsort(input=probs_adv, dim=-1)[-2:]\n",
    "    \n",
    "    # get the max probability for the incorrect class prediction. basically if the highest probability is for the correct class, get the next higest probability\n",
    "    labels_new = torch.where(tmp1[:,-1] == labels, input=tmp1[:,-2], other=tmp1[:,-1])\n",
    "\n",
    "    bce_loss = F.cross_entropy(logits_adv, labels) + F.nll_loss(torch.log(1 - probs_adv + 1e-12), labels_new)\n",
    "\n",
    "\n",
    "    # KL term\n",
    "    kl = nn.KLDivLoss(reduction='none')\n",
    "    probs_clean = F.softmax(logits_clean, dim=-1)\n",
    "    probs_true = torch.gather(probs_clean, dim=1, index=(labels.unsqueeze(1)).long()).squeeze()\n",
    "    reg_loss = torch.sum(torch.sum(kl(torch.log(probs_adv + 1e-12), probs_clean), dim=1) * 1.000001 - probs_true) / labels.size[0]\n",
    "\n",
    "    loss = bce_loss + float(lambda_reg) * reg_loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "    # reg_loss = torch.sum(torch.sum(kl(torch.log(probs_adv + 1e-12), probs_nat), dim=1) * (1 - true_probs)) / inputs.size(0)\n",
    "\n",
    "    # loss_robust = (1.0 / batch_size) * torch.sum(torch.sum(kl(torch.log(adv_probs + 1e-12), nat_probs), dim=1) * (1.0000001 - true_probs))\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def adv_train_one_epoch(model,  dataloader, criterion, optimizer, config, device=\"cuda\", max_grad_norm=None):\n",
    "    #model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        model.train()\n",
    "        x_adv = create_adv_samples(model, inputs=images, labels=labels, config=config, random_start=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        logits_clean = model(images)\n",
    "        logits_adv = model(x_adv)\n",
    "\n",
    "        loss = mart_loss(logits_clean, logits_adv, labels, lambda_reg=config[\"lambda_reg\"])\n",
    "        loss.backward()\n",
    "        \n",
    "        if max_grad_norm:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = torch.argmax(outputs.detach(), -1)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        total_samples += images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects / total_samples\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
