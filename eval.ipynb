{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchmetrics.classification import Accuracy\n",
    "# import wandb\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resnet Model\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.residual = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = F.relu(self.bn2(self.conv2(out)), inplace=True)\n",
    "        out = out + self.residual(x)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block: BasicBlock, num_blocks: list[int], num_classes: int=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer0 = self.make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer1 = self.make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer2 = self.make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer3 = self.make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "\n",
    "    \n",
    "    def make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "\n",
    "        layers.append(block(self.in_channels, out_channels, stride=stride))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = self.layer0(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        logits = self.linear(out)\n",
    "        return logits\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_model = ResNet18().to(device)\n",
    "base_model_path = \"./notebooks/checkpoints/model_epoch_87_valloss_0.3925.pth\"\n",
    "checkpoint = torch.load(base_model_path, weights_only=True)\n",
    "clean_model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cifar = datasets.CIFAR10(root='./data', download=True, train=False, transform=transforms.ToTensor())\n",
    "test_loader_cifar = DataLoader(dataset=test_cifar, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchattacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fgsm = torchattacks.FGSM(clean_model, eps=8/255)\n",
    "# pgd20 = torchattacks.PGD(clean_model, eps=8/255, alpha=0.003137, steps=20, random_start=True)\n",
    "# cw_inf = torchattacks.CW(clean_model, c=1e-4, kappa=0, steps=1000)\n",
    "\n",
    "# attacks= [\"natural\", fgsm, pgd20] #, cw_inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNet18().to(device)\n",
    "# check_path = \"/scratch/joluseti/projects/adversarial_ml/notebooks/checkpoints/\"\n",
    "# checkpoint = torch.load(check_path, weights_only=True)\n",
    "# model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet_2(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet_2(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_model = ResNet18().to(device)\n",
    "# adv_model_path = \"/scratch/joluseti/projects/adversarial_ml/notebooks/adv_checkpoints/model_epoch_81.pth\"\n",
    "adv_model_path =\"/scratch/joluseti/projects/MART/resnet_new/model-res-epoch100.pt\"\n",
    "checkpoint = torch.load(adv_model_path, weights_only=True)\n",
    "# adv_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "adv_model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pgd_attack(model, inputs, labels, epsilon=0.031, step_size=0.007, num_steps=10, random_start=True, device=\"cuda\"):\n",
    "#     \"\"\"\n",
    "#     Performs a Projected Gradient Descent (PGD) attack on a model.\n",
    "#     PGD is an iterative adversarial attack that perturbs the input data to maximize\n",
    "#     the loss, constrained by a maximum L-infinity perturbation of epsilon.\n",
    "#     Args:\n",
    "#         model: The neural network model to attack.\n",
    "#         inputs: Input tensor of shape (batch_size, channels, height, width).\n",
    "#         labels: True labels corresponding to the inputs.\n",
    "#         epsilon: Maximum L-infinity norm of the perturbation (default: 0.031).\n",
    "#         step_size: Step size for each iteration (default: 0.007).\n",
    "#         num_steps: Number of PGD iterations (default: 10).\n",
    "#         random_start: Whether to start with a random perturbation (default: True).\n",
    "#         device: Device to perform the attack on (default: \"cuda\").\n",
    "#     Returns:\n",
    "#         torch.Tensor: Adversarial examples of the same shape as inputs.\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     # Keep original clean samples\n",
    "#     x_clean = inputs.clone().detach()\n",
    "\n",
    "#     delta = torch.rand_like(inputs, device=device) * 2 * epsilon - epsilon\n",
    "#     delta = torch.clamp(delta, -epsilon, epsilon)\n",
    "#     delta.requires_grad = True\n",
    "\n",
    "#     for step in range(num_steps):\n",
    "#         x_adv = x_clean + delta\n",
    "        \n",
    "#         # for stable batch norm stats and to disable dropout\n",
    "#         with torch.enable_grad():\n",
    "#             outputs = model(x_adv)\n",
    "#         loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "#         grad = torch.autograd.grad(loss, [delta])[0]\n",
    "#         delta = delta.detach() + step_size * torch.sign(grad)\n",
    "#         delta = torch.clamp(delta, -epsilon, epsilon)\n",
    "\n",
    "#         # clamp adversarial sample to valid pixel range        \n",
    "#         x_adv_clamped = torch.clamp(x_clean + delta, 0.0, 1.0)\n",
    "        \n",
    "#         # get accurate delat from clamped x\n",
    "#         delta = x_adv_clamped - x_clean\n",
    "#         delta = delta.detach()\n",
    "        \n",
    "#         if step < num_steps - 1:\n",
    "#             delta.requires_grad = True\n",
    "    \n",
    "#     # final adversarial sample\n",
    "#     x_adv = (x_clean + delta).detach()\n",
    "#     return x_adv\n",
    "\n",
    "\n",
    "# def validate(model, dataloader, metrics, num_steps=20, epsilon=0.031, step_size=0.003, device=\"cuda\"):\n",
    "#     metrics.reset()\n",
    "#     model.eval()\n",
    "\n",
    "#     for images, labels in tqdm(dataloader, desc=f\"Validation\"):\n",
    "#         images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        \n",
    "#         # ---------- clean accuracy ----------\n",
    "#         with torch.no_grad():\n",
    "#             logits_clean = model(images)\n",
    "\n",
    "#         metrics[\"val/clean_acc\"].update(logits_clean.argmax(dim=-1), labels)\n",
    "\n",
    "#         # ---------- adversarial accuracy ----------\n",
    "#         x_adv = pgd_attack(model, inputs=images, labels=labels, epsilon=epsilon, step_size=step_size, num_steps=num_steps)\n",
    "#         with torch.no_grad():\n",
    "#             logits_adv = model(x_adv)        \n",
    "#         metrics[\"val/adv_acc\"].update(logits_adv.argmax(dim=-1), labels)\n",
    "\n",
    "#     return metrics.compute()\n",
    "\n",
    "# from torchmetrics import Accuracy, MetricCollection\n",
    "\n",
    "# val_metrics   = MetricCollection({\n",
    "#         \"clean_acc\" : Accuracy(task=\"multiclass\", num_classes=10),\n",
    "#         \"adv_acc\"   : Accuracy(task=\"multiclass\", num_classes=10)}).to(device).clone(prefix=\"val/\")\n",
    "\n",
    "# val_stats = validate(model=adv_model,\n",
    "#                     dataloader=test_loader_cifar,\n",
    "#                     metrics=val_metrics)\n",
    "\n",
    "# val_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(attacks, model, dataloader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    results = {}\n",
    "\n",
    "    for attack in attacks:\n",
    "        correct = 0\n",
    "        total   = 0\n",
    "        name    = attack if attack==\"natural\" else attack.__class__.__name__\n",
    "        print(f\"\\n→ Evaluating {name}\")\n",
    "\n",
    "        for images, labels in tqdm(dataloader, desc=name):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # natural accuracy\n",
    "            if attack==\"natural\":\n",
    "                with torch.no_grad():\n",
    "                    preds = model(images).argmax(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "\n",
    "            # adversarial accuracy\n",
    "            else:\n",
    "                # 4) check the magnitude once\n",
    "                adv = attack(images, labels)\n",
    "                δ = (adv-images).view(images.size(0),-1).abs().max(1)[0]\n",
    "                # print(f\"  avg perturb {δ.mean():.4f}\")\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    preds = model(adv).argmax(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "\n",
    "            total += labels.size(0)\n",
    "\n",
    "        acc = 100*correct/total\n",
    "        results[name] = acc\n",
    "        print(f\"  → {name} accuracy = {acc:.2f}%\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- basic pre‑activation block ------------------------------------------\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride, drop_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.equal_io = (in_ch == out_ch)\n",
    "\n",
    "        self.bn1   = nn.BatchNorm2d(in_ch)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "        self.bn2   = nn.BatchNorm2d(out_ch)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
    "\n",
    "        self.drop_rate = drop_rate\n",
    "        self.shortcut  = None if self.equal_io else nn.Conv2d(\n",
    "            in_ch, out_ch, 1, stride=stride, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.bn1(x)) if self.equal_io else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.relu2(self.bn2(out))\n",
    "        if self.drop_rate > 0:\n",
    "            out = F.dropout(out, p=self.drop_rate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return (x if self.equal_io else self.shortcut(x)) + out\n",
    "\n",
    "\n",
    "# -------- stack of BasicBlocks -----------------------------------------------\n",
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, n_layers, in_ch, out_ch, stride, drop_rate):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            layers.append(\n",
    "                BasicBlock(\n",
    "                    in_ch if i == 0 else out_ch,\n",
    "                    out_ch,\n",
    "                    stride if i == 0 else 1,\n",
    "                    drop_rate,\n",
    "                )\n",
    "            )\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "# -------- Wide ResNet ---------------------------------------------------------\n",
    "class WideResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Wide ResNet (WRN‑d‑k)        – Zagoruyko & Komodakis, 2016\n",
    "    depth d = 6n+4, widen factor k.\n",
    "\n",
    "    Example: WRN‑34‑10  -> depth=34, widen_factor=10\n",
    "    \"\"\"\n",
    "    def __init__(self, depth=34, widen_factor=10, num_classes=10, drop_rate=0.0):\n",
    "        super().__init__()\n",
    "        assert (depth - 4) % 6 == 0, \"depth must be 6n+4\"\n",
    "        n = (depth - 4) // 6\n",
    "\n",
    "        ch = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n",
    "\n",
    "        self.conv1  = nn.Conv2d(3, ch[0], 3, padding=1, bias=False)\n",
    "        self.block1 = NetworkBlock(n, ch[0], ch[1], stride=1, drop_rate=drop_rate)\n",
    "        self.block2 = NetworkBlock(n, ch[1], ch[2], stride=2, drop_rate=drop_rate)\n",
    "        self.block3 = NetworkBlock(n, ch[2], ch[3], stride=2, drop_rate=drop_rate)\n",
    "\n",
    "        self.bn     = nn.BatchNorm2d(ch[3])\n",
    "        self.relu   = nn.ReLU(inplace=True)\n",
    "        self.pool   = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc     = nn.Linear(ch[3], num_classes)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1.0)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)          # 32×32 → 32×32\n",
    "        x = self.block1(x)         # 32×32\n",
    "        x = self.block2(x)         # 16×16\n",
    "        x = self.block3(x)         # 8×8\n",
    "        x = self.relu(self.bn(x))\n",
    "        x = self.pool(x).flatten(1)  # global avg‑pool\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "wrn_model = WideResNet().to(device)\n",
    "base_model_path = \"/scratch/joluseti/projects/adversarial_ml/results/models/wrn/main/best_valAcc=0.445.pth\"\n",
    "checkpoint = torch.load(base_model_path, weights_only=True)\n",
    "stripped_check = {\n",
    "    k.replace(\"_orig_mod.\",\"\"):v for k,v in checkpoint[\"model_state\"].items()\n",
    "}\n",
    "wrn_model.load_state_dict(stripped_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Evaluating natural\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "natural: 100%|██████████| 79/79 [00:14<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → natural accuracy = 64.43%\n",
      "\n",
      "→ Evaluating FGSM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM: 100%|██████████| 79/79 [00:42<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → FGSM accuracy = 45.73%\n",
      "\n",
      "→ Evaluating PGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PGD: 100%|██████████| 79/79 [09:33<00:00,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → PGD accuracy = 43.94%\n",
      "{'natural': 64.43, 'FGSM': 45.73, 'PGD': 43.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = wrn_model.to(device).eval()\n",
    "# 1) use the same model instance\n",
    "# 2) pick a sane step size\n",
    "fgsm  = torchattacks.FGSM(model, eps=8/255)\n",
    "pgd20 = torchattacks.PGD(model,\n",
    "                         eps=8/255,\n",
    "                         alpha=2/255,\n",
    "                         steps=20,\n",
    "                         random_start=True)\n",
    "\n",
    "attacks= [\"natural\", fgsm, pgd20] #, cw_inf]\n",
    "\n",
    "\n",
    "res = evaluate_model(attacks, model, test_loader_cifar)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
